{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\rishi\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import date\n",
    "import calendar\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "from sklearn.ensemble import GradientBoostingRegressor  \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn import cross_validation \n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./Documents/energydata_complete.csv',index_col='date',header=0)\n",
    "df['datetime'] = df.index\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['day_of_week']=df['datetime'].dt.strftime('%w').astype('int64')\n",
    "df['month']=df['datetime'].dt.strftime('%m').astype('int64')\n",
    "df['hour']=df['datetime'].dt.hour\n",
    "df['day_number']=df['datetime'].dt.day\n",
    "df['Week_no'] = df['datetime'].dt.strftime('%W').astype('int64')\n",
    "df['min'] = df['datetime'].dt.minute\n",
    "df['day_of_week']=df['day_of_week'].apply(str)\n",
    "df['hour']=df['hour'].apply(str)\n",
    "df['min']=df['min'].apply(str)\n",
    "df['period']=df[['day_of_week','hour','min']].apply(lambda x:''.join(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = df.groupby(['date','month','day_of_week','hour','day_number','min','datetime','period']).mean()\n",
    "phase[\"Total\"]=phase[\"Appliances\"] + phase[\"lights\"]\n",
    "phase = phase.reset_index()\n",
    "phase.set_index('date', inplace=True)\n",
    "phase['datetime'] = df.index\n",
    "phase['datetime'] = pd.to_datetime(phase['datetime'])\n",
    "phase['day_of_week']=phase['day_of_week'].apply(int)\n",
    "phase['hour']=phase['hour'].apply(int)\n",
    "phase['min']=phase['min'].apply(int)\n",
    "phase['period']=phase['period'].apply(int)\n",
    "phase['Press_mm_hg'] = np.log(phase['Press_mm_hg'])\n",
    "phase['Visibility'] = np.log(phase['Visibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "phase1 = phase\n",
    "phase1.drop(['datetime','Total','rv1','rv2'],axis=1,inplace=True)\n",
    "y = phase1[\"Appliances\"]\n",
    "X=phase1.drop(\"Appliances\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'featuretools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8a54032b3ccd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfeaturetools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'featuretools'"
     ]
    }
   ],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_featuretools = df.groupby(['date','month','day_of_week','hour','day_number','min','period']).mean()\n",
    "phase_featuretools = phase_featuretools.reset_index()\n",
    "phase_featuretools['day_of_week']=phase_featuretools['day_of_week'].apply(int)\n",
    "phase_featuretools['hour']=phase_featuretools['hour'].apply(int)\n",
    "phase_featuretools['min']=phase_featuretools['min'].apply(int)\n",
    "phase_featuretools['period']=phase_featuretools['period'].apply(int)\n",
    "phase_featuretools['date'] = pd.to_datetime(phase_featuretools['date'])\n",
    "phase_featuretools['Press_mm_hg'] = np.log(phase_featuretools['Press_mm_hg'])\n",
    "phase_featuretools['Visibility'] = np.log(phase_featuretools['Visibility'])\n",
    "phase_featuretools = phase_featuretools.drop(['rv1','rv2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_featuretools = phase_featuretools[['date','Appliances']]\n",
    "X_featuretools = phase_featuretools.drop(['Appliances'],axis=1)\n",
    "entities ={\"appliances\" :(y_featuretools,\"date\"),\n",
    "          \"rest\" :(X_featuretools,\"date\")}\n",
    "relationships = [(\"appliances\",\"date\",\"rest\",\"date\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_app,features_defs = ft.dfs(entities=entities,relationships=relationships,target_entity=\"appliances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_app1 = feature_matrix_app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Appliances                  int64\n",
       "SUM(rest.month)             int64\n",
       "SUM(rest.day_of_week)       int64\n",
       "SUM(rest.hour)              int64\n",
       "SUM(rest.day_number)        int64\n",
       "SUM(rest.min)               int64\n",
       "SUM(rest.period)            int64\n",
       "SUM(rest.lights)            int64\n",
       "SUM(rest.T1)              float64\n",
       "SUM(rest.RH_1)            float64\n",
       "SUM(rest.T2)              float64\n",
       "SUM(rest.RH_2)            float64\n",
       "SUM(rest.T3)              float64\n",
       "SUM(rest.RH_3)            float64\n",
       "SUM(rest.T4)              float64\n",
       "SUM(rest.RH_4)            float64\n",
       "SUM(rest.T5)              float64\n",
       "SUM(rest.RH_5)            float64\n",
       "SUM(rest.T6)              float64\n",
       "SUM(rest.RH_6)            float64\n",
       "SUM(rest.T7)              float64\n",
       "SUM(rest.RH_7)            float64\n",
       "SUM(rest.T8)              float64\n",
       "SUM(rest.RH_8)            float64\n",
       "SUM(rest.T9)              float64\n",
       "SUM(rest.RH_9)            float64\n",
       "SUM(rest.T_out)           float64\n",
       "SUM(rest.Press_mm_hg)     float64\n",
       "SUM(rest.RH_out)          float64\n",
       "SUM(rest.Windspeed)       float64\n",
       "                           ...   \n",
       "MEAN(rest.hour)             int64\n",
       "MEAN(rest.day_number)       int64\n",
       "MEAN(rest.min)              int64\n",
       "MEAN(rest.period)           int64\n",
       "MEAN(rest.lights)           int64\n",
       "MEAN(rest.T1)             float64\n",
       "MEAN(rest.RH_1)           float64\n",
       "MEAN(rest.T2)             float64\n",
       "MEAN(rest.RH_2)           float64\n",
       "MEAN(rest.T3)             float64\n",
       "MEAN(rest.RH_3)           float64\n",
       "MEAN(rest.T4)             float64\n",
       "MEAN(rest.RH_4)           float64\n",
       "MEAN(rest.T5)             float64\n",
       "MEAN(rest.RH_5)           float64\n",
       "MEAN(rest.T6)             float64\n",
       "MEAN(rest.RH_6)           float64\n",
       "MEAN(rest.T7)             float64\n",
       "MEAN(rest.RH_7)           float64\n",
       "MEAN(rest.T8)             float64\n",
       "MEAN(rest.RH_8)           float64\n",
       "MEAN(rest.T9)             float64\n",
       "MEAN(rest.RH_9)           float64\n",
       "MEAN(rest.T_out)          float64\n",
       "MEAN(rest.Press_mm_hg)    float64\n",
       "MEAN(rest.RH_out)         float64\n",
       "MEAN(rest.Windspeed)      float64\n",
       "MEAN(rest.Visibility)     float64\n",
       "MEAN(rest.Tdewpoint)      float64\n",
       "MEAN(rest.Week_no)          int64\n",
       "Length: 193, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_app1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_featuretools = y_featuretools.drop('date',axis=1)\n",
    "y_featuretools = y_featuretools.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix_app1, y_featuretools, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(name,X_train, y_train, X_test, y_test):\n",
    "    global metric\n",
    "    n = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "teston = models('featuretools',X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "teston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d07c4b9f1a1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Fit only to the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Now apply the transformations to the data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \"\"\"\n\u001b[0;32m    611\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m--> 612\u001b[1;33m                         warn_on_dtype=True, estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)\n",
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "teston = models('After Scaling_featuretools',X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
