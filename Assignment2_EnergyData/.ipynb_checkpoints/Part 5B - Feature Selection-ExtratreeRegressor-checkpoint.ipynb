{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boruta\n",
      "  Downloading https://files.pythonhosted.org/packages/35/03/ca2b7e352bf1f0e2dd0e17e1b8c92f75dbb9f218d36eba4e894efa2a0478/Boruta-0.1.5.tar.gz (55kB)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\hp\\anaconda\\lib\\site-packages (from boruta)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\users\\hp\\anaconda\\lib\\site-packages (from boruta)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\hp\\anaconda\\lib\\site-packages (from boruta)\n",
      "Building wheels for collected packages: boruta\n",
      "  Running setup.py bdist_wheel for boruta: started\n",
      "  Running setup.py bdist_wheel for boruta: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\5c\\5a\\72\\13e8ea10ba10e22e9ca7f76f8b451c9f98fa190d428c8857dd\n",
      "Successfully built boruta\n",
      "Installing collected packages: boruta\n",
      "Successfully installed boruta-0.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n",
      "You are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/6c/f1806e5b31d65a195bcd94fd80079318d5a9e54c2239b395404c25496792/TPOT-0.9.5.tar.gz (891kB)\n",
      "Collecting numpy>=1.12.1 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/70/7096a735b27359dbc0c380b23b9c9bd05fea62233f95849c43a6b02c5f40/numpy-1.15.4-cp36-none-win_amd64.whl (13.5MB)\n",
      "Collecting scipy>=0.19.0 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/e2/364f0bcc641aeff79d743c732769d5dc31a1e78c27699229431412c4b425/scipy-1.1.0-cp36-none-win_amd64.whl (31.1MB)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in c:\\users\\hp\\anaconda\\lib\\site-packages (from tpot)\n",
      "Collecting deap>=1.0 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/af/29/e7f2ecbe02997b16a768baed076f5fc4781d7057cd5d9adf7c94027845ba/deap-1.2.2.tar.gz (936kB)\n",
      "Collecting update_checker>=0.16 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/c9/ab11855af164d03be0ff4fddd4c46a5bd44799a9ecc1770e01a669c21168/update_checker-0.16-py2.py3-none-any.whl\n",
      "Collecting tqdm>=4.11.2 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Collecting stopit>=1.1.1 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
      "Collecting pandas>=0.20.2 (from tpot)\n",
      "  Downloading https://files.pythonhosted.org/packages/0e/67/def5bfaf4d3324fdb89048889ec523c0903c5efab1a64c8dbe0ac8eec13c/pandas-0.23.4-cp36-cp36m-win_amd64.whl (7.7MB)\n",
      "Requirement already satisfied: requests>=2.3.0 in c:\\users\\hp\\anaconda\\lib\\site-packages (from update_checker>=0.16->tpot)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\hp\\anaconda\\lib\\site-packages (from pandas>=0.20.2->tpot)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\hp\\anaconda\\lib\\site-packages (from pandas>=0.20.2->tpot)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda\\lib\\site-packages (from python-dateutil>=2.5.0->pandas>=0.20.2->tpot)\n",
      "Building wheels for collected packages: tpot, deap, stopit\n",
      "  Running setup.py bdist_wheel for tpot: started\n",
      "  Running setup.py bdist_wheel for tpot: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\97\\86\\27\\698a1366f854d2344fd0f7ee9ef57c8044ec02f182c8a0431e\n",
      "  Running setup.py bdist_wheel for deap: started\n",
      "  Running setup.py bdist_wheel for deap: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\22\\ea\\bf\\dc7c8a2262025a0ab5da9ef02282c198be88902791ca0c6658\n",
      "  Running setup.py bdist_wheel for stopit: started\n",
      "  Running setup.py bdist_wheel for stopit: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\3c\\85\\2b\\2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
      "Successfully built tpot deap stopit\n",
      "Installing collected packages: numpy, scipy, deap, update-checker, tqdm, stopit, pandas, tpot\n",
      "  Found existing installation: numpy 1.11.3\n",
      "    Uninstalling numpy-1.11.3:\n",
      "      Successfully uninstalled numpy-1.11.3\n",
      "  Found existing installation: scipy 0.18.1\n",
      "    Uninstalling scipy-0.18.1:\n",
      "      Successfully uninstalled scipy-0.18.1\n",
      "  Found existing installation: pandas 0.19.2\n",
      "    Uninstalling pandas-0.19.2:\n",
      "      Successfully uninstalled pandas-0.19.2\n",
      "Successfully installed deap-1.2.2 numpy-1.15.4 pandas-0.23.4 scipy-1.1.0 stopit-1.1.2 tpot-0.9.5 tqdm-4.28.1 update-checker-0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "  Cache entry deserialization failed, entry ignored\n",
      "You are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda\\lib\\site-packages\\deap\\tools\\_hypervolume\\pyhv.py:33: ImportWarning: Falling back to the python version of hypervolume module. Expect this to be very slow.\n",
      "  \"module. Expect this to be very slow.\", ImportWarning)\n",
      "C:\\Users\\HP\\Anaconda\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\HP\\Anaconda\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\HP\\Anaconda\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\HP\\Anaconda\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\HP\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "## imporing the librarires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot import TPOTRegressor\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import*\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>Appliances</th>\n",
       "      <th>lights</th>\n",
       "      <th>Kitchen_Temp</th>\n",
       "      <th>Kitchen_Hum</th>\n",
       "      <th>LivingRoom_Temp</th>\n",
       "      <th>LivingRoom_Hum</th>\n",
       "      <th>LaundryRoom_Temp</th>\n",
       "      <th>LaundryRoom_Hum</th>\n",
       "      <th>...</th>\n",
       "      <th>Visibility</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Month_Number</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date_number</th>\n",
       "      <th>Weekday_number</th>\n",
       "      <th>Weekday_Column</th>\n",
       "      <th>Energy_consumed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-11 17:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>17:00:00</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-11 17:10:00</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.166667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>17:10:00</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-11 17:20:00</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>...</td>\n",
       "      <td>55.333333</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>17:20:00</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-11 17:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>17:30:00</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-11 17:40:00</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>17:40:00</td>\n",
       "      <td>2016-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  Appliances  lights  Kitchen_Temp  \\\n",
       "0           0  2016-01-11 17:00:00          60      30         19.89   \n",
       "1           1  2016-01-11 17:10:00          60      30         19.89   \n",
       "2           2  2016-01-11 17:20:00          50      30         19.89   \n",
       "3           3  2016-01-11 17:30:00          50      40         19.89   \n",
       "4           4  2016-01-11 17:40:00          60      40         19.89   \n",
       "\n",
       "   Kitchen_Hum  LivingRoom_Temp  LivingRoom_Hum  LaundryRoom_Temp  \\\n",
       "0    47.596667             19.2       44.790000             19.79   \n",
       "1    46.693333             19.2       44.722500             19.79   \n",
       "2    46.300000             19.2       44.626667             19.79   \n",
       "3    46.066667             19.2       44.590000             19.79   \n",
       "4    46.333333             19.2       44.530000             19.79   \n",
       "\n",
       "   LaundryRoom_Hum       ...         Visibility  Tdewpoint        rv1  \\\n",
       "0        44.730000       ...          63.000000        5.3  13.275433   \n",
       "1        44.790000       ...          59.166667        5.2  18.606195   \n",
       "2        44.933333       ...          55.333333        5.1  28.642668   \n",
       "3        45.000000       ...          51.500000        5.0  45.410389   \n",
       "4        45.000000       ...          47.666667        4.9  10.084097   \n",
       "\n",
       "   Day_of_week  Month_Number      Time  Date_number  Weekday_number  \\\n",
       "0       Monday             1  17:00:00   2016-01-11               0   \n",
       "1       Monday             1  17:10:00   2016-01-11               0   \n",
       "2       Monday             1  17:20:00   2016-01-11               0   \n",
       "3       Monday             1  17:30:00   2016-01-11               0   \n",
       "4       Monday             1  17:40:00   2016-01-11               0   \n",
       "\n",
       "   Weekday_Column  Energy_consumed  \n",
       "0               0               90  \n",
       "1               0               90  \n",
       "2               0               80  \n",
       "3               0               90  \n",
       "4               0              100  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## importing the dataset\n",
    "dataset = pd.read_csv(\"./Documents/Revised_Data.csv\")\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop('date',1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Date_number',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Time',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Day_of_week',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## X are the varibles used for predictions\n",
    "## Y is the target\n",
    "x = dataset.iloc[:,3:31].values\n",
    "y = dataset.iloc[:,31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False,\n",
       "           random_state=<module 'numpy.random' from 'C:\\\\Users\\\\HP\\\\Anaconda\\\\lib\\\\site-packages\\\\numpy\\\\random\\\\__init__.py'>,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Fitting the data in random forest algorithm by splitting it into training and testing dataset\n",
    "randomForest = RandomForestRegressor(n_estimators=100,random_state=np.random)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=np.random)\n",
    "randomForest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define Boruta feature selection method\n",
    "feature_selector = BorutaPy(randomForest, n_estimators='auto', verbose=2, random_state=np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t28\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t0\n",
      "Rejected: \t5\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t23\n",
      "Tentative: \t0\n",
      "Rejected: \t5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all relevant features\n",
    "feature_selector.fit(x,y)\n",
    "feature_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_selector = BorutaPy(regressor,n_estimators='auto', verbose=2, random_state=np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'max_depth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4a112c82a62b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;31m# number of features that aren't rejected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mnot_rejected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_reg\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                 \u001b[0mn_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tree_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_rejected\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_get_tree_num\u001b[1;34m(self, n_feat)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_tree_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_feat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdepth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m             \u001b[0mdepth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'max_depth'"
     ]
    }
   ],
   "source": [
    "feature_selector.fit(x,y)\n",
    "feature_selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda\\lib\\importlib\\_bootstrap.py:205: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n",
      "Generation 1 - Current best internal CV score: -5866.56965676732\n",
      "Generation 2 - Current best internal CV score: -5866.56965676732\n",
      "Generation 3 - Current best internal CV score: -5733.67471080355\n",
      "Generation 4 - Current best internal CV score: -5318.705441811093\n",
      "Generation 5 - Current best internal CV score: -5095.624828524819\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(input_matrix, bootstrap=False, max_features=0.8, min_samples_leaf=2, min_samples_split=4, n_estimators=100)\n",
      "-3980.333783408918\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTRegressor(generations=5, population_size=50, verbosity=2)\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1= dataset[['T1','RH_1','T2','RH_2','RH_3','T4','RH_4','T5','RH_5','T6','RH_6',\t\n",
    "'T7','RH_7','T8','RH_8','T9','RH_9','T_out','Press_mm_hg','RH_out','Windspeed','Visibility','Tdewpoint','rv1',\t\n",
    "'Month_Number','Weekday_number','Weekday_Column'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1=dataset['Energy_consumed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 1, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ranking of features\n",
    "feat_selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44.79      , 19.79      , 44.73      , ...,  5.3       ,\n",
       "         1.        ,  0.        ],\n",
       "       [44.7225    , 19.79      , 44.79      , ...,  5.2       ,\n",
       "         1.        ,  0.        ],\n",
       "       [44.62666667, 19.79      , 44.93333333, ...,  5.1       ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [42.76857143, 27.05      , 41.69      , ..., 13.26666667,\n",
       "         5.        ,  4.        ],\n",
       "       [43.036     , 26.89      , 41.29      , ..., 13.23333333,\n",
       "         5.        ,  4.        ],\n",
       "       [42.97142857, 26.82333333, 41.15666667, ..., 13.2       ,\n",
       "         5.        ,  4.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(X)\n",
    "X_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##FORWARD SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  RH_1                           with p-value 6.52549e-153\n",
      "resulting features:\n",
      "['RH_1']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "def stepwise_selection(X1, y1, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X1.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y1, sm.add_constant(X1)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "            if not changed:\n",
    "                break\n",
    "            return included\n",
    "\n",
    "result = stepwise_selection(X1, y1)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##BACKWARD SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting features:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# import statsmodels.api as sm\n",
    "def stepwise_selection(X1, y1, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "        included = list(initial_list)\n",
    "        while True:\n",
    "            changed=False\n",
    "import statsmodels.api as sm\n",
    "def stepwise_selection(X1, y1, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "         # backward step\n",
    "        model = sm.OLS(y1, sm.add_constant(pd.DataFrame(X1[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(X1, y1)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##EXHAUSTIVE SEARCH METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  RH_out                         with p-value 2.22825e-92\n",
      "Add  RH_1                           with p-value 1.2589e-85\n",
      "Add  RH_8                           with p-value 4.48028e-143\n",
      "Add  RH_2                           with p-value 1.8353e-101\n",
      "Add  Month_Number                   with p-value 1.90285e-35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: FutureWarning: 'argmax' is deprecated, use 'idxmax' instead. The behavior of 'argmax'\n",
      "will be corrected to return the positional maximum in the future.\n",
      "Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop RH_out                         with p-value 0.616498\n",
      "Add  T8                             with p-value 8.02883e-24\n",
      "Add  T9                             with p-value 2.14571e-28\n",
      "Add  Windspeed                      with p-value 3.03944e-14\n",
      "Drop Month_Number                   with p-value 0.122486\n",
      "Add  RH_7                           with p-value 1.23096e-07\n",
      "Add  T6                             with p-value 5.65006e-07\n",
      "Add  T_out                          with p-value 1.51695e-12\n",
      "Add  RH_3                           with p-value 1.32294e-10\n",
      "Add  T2                             with p-value 5.623e-08\n",
      "Add  T1                             with p-value 3.16751e-37\n",
      "Add  Tdewpoint                      with p-value 2.51191e-06\n",
      "Add  T4                             with p-value 2.30048e-07\n",
      "Add  Month_Number                   with p-value 0.000152685\n",
      "Add  T5                             with p-value 0.000225156\n",
      "resulting features:\n",
      "['RH_1', 'RH_8', 'RH_2', 'T8', 'T9', 'Windspeed', 'RH_7', 'T6', 'T_out', 'RH_3', 'T2', 'T1', 'Tdewpoint', 'T4', 'Month_Number', 'T5']\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "def stepwise_selection(X1, y1, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.01, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X1.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y1, sm.add_constant(pd.DataFrame(X1[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y1, sm.add_constant(pd.DataFrame(X1[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n",
    "result = stepwise_selection(X1, y1)\n",
    "\n",
    "print('resulting features:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
