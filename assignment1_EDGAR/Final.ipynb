{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - name '__file__' is not defined\n",
      "Enter Year2008\n",
      "Enter CIK Number  51143\n",
      "Enter the accession number 000005114313000007\n",
      "accesskey AKIAJB3EK3YZROUUILYQ\n",
      "secretAccessKey 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\n",
      "DEBUG - Using access key provided by client.\n",
      "DEBUG - Using secret key provided by client.\n",
      "Connected to S3\n",
      "INFO - Initializing zip download.\n",
      "INFO - Log file log20080101.zip successfully downloaded\n",
      "INFO - Log file log20080201.zip successfully downloaded\n",
      "INFO - Log file log20080301.zip successfully downloaded\n",
      "INFO - Log file log20080401.zip successfully downloaded\n",
      "INFO - Log file log20080501.zip successfully downloaded\n",
      "INFO - Log file log20080601.zip successfully downloaded\n",
      "INFO - Log file log20080701.zip successfully downloaded\n",
      "INFO - Log file log20080801.zip successfully downloaded\n",
      "INFO - Log file log20080901.zip successfully downloaded\n",
      "INFO - Log file log20081001.zip successfully downloaded\n",
      "INFO - Log file log20081101.zip successfully downloaded\n",
      "INFO - Log file log20081201.zip successfully downloaded\n",
      "INFO - All log files downloaded for 2008\n",
      "INFO - Zip files successfully extracted to folder: downloaded_zips_unzipped.\n",
      "INFO - All the csv read into individual dataframes\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080101.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size           3729\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      125368\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080101.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080101.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080101.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080201.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          20662\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      222875\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080201.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080201.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080201.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080301.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size           5620\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      325107\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080301.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080301.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080301.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080401.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          30704\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      347456\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080401.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080401.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080401.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080501.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          21581\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      631250\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080501.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080501.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080501.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080601.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size           5763\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      224287\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080601.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080601.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080601.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080701.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          21492\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      226706\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080701.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080701.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080701.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080801.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          18936\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      278679\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080801.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080801.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080801.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20080901.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          13933\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      157893\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080901.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080901.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20080901.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20081001.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          37738\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      234603\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081001.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081001.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081001.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20081101.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              0\n",
      "size          10992\n",
      "idx               0\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              0\n",
      "crawler           0\n",
      "browser      263144\n",
      "dtype: int64 \n",
      "INFO - There are 0 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081101.csv\n",
      "INFO - There are 0 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081101.csv\n",
      "INFO - There are 0 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081101.csv\n",
      "INFO - Count of Null values for downloaded_zips_unzipped\\log20081201.csv in all the variables:\n",
      "ip                0\n",
      "date              0\n",
      "time              0\n",
      "zone              0\n",
      "cik               0\n",
      "accession         0\n",
      "extention         0\n",
      "code              2\n",
      "size          32709\n",
      "idx               2\n",
      "norefer           0\n",
      "noagent           0\n",
      "find              2\n",
      "crawler           2\n",
      "browser      219816\n",
      "dtype: int64 \n",
      "INFO - There are 2 idx which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081201.csv\n",
      "INFO - There are 2 norefer which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081201.csv\n",
      "INFO - There are 2 noagent which are not 0 or 1 in the log file downloaded_zips_unzipped\\log20081201.csv\n",
      "INFO - Rows removed where ip, date, time, cik or accession were null.\n",
      "INFO - NaN values in browser replaced with maximum count browser.\n",
      "INFO - NaN values in idx replaced with maximum count idx.\n",
      "INFO - NaN values in code replaced with maximum count code.\n",
      "INFO - NaN values in norefer replaced with 0.\n",
      "INFO - NaN values in noagent replaced with 0.\n",
      "INFO - NaN values in find replaced with maximum count find.\n",
      "INFO - NaN values in crawler replaced with 0.\n",
      "INFO - NaN values in extension replaced with maximum count extension.\n",
      "INFO - NaN values in zone replaced with maximum count zone.\n",
      "INFO - NaN values in size replaced with mean value of size.\n",
      "INFO - New column added to dataframe: Mean of size.\n",
      "INFO - New column added to dataframe: Max count of browser.\n",
      "INFO - New column added to dataframe: Count of distinct ip per month.\n",
      "INFO - New column added to dataframe: Count of distinct cik per month.\n",
      "INFO - All dataframes of csvs are combined and exported as csv: main_csv.csv.\n",
      "INFO - Compiled csv and log file zipped\n",
      "DEBUG - path=/\n",
      "DEBUG - auth_path=/akiajb3ek3yzrouuilyq20181012210958353454/\n",
      "DEBUG - Method: PUT\n",
      "DEBUG - Path: /\n",
      "DEBUG - Data: \n",
      "DEBUG - Headers: {}\n",
      "DEBUG - Host: akiajb3ek3yzrouuilyq20181012210958353454.s3.amazonaws.com:443\n",
      "DEBUG - Port: 443\n",
      "DEBUG - Params: {}\n",
      "DEBUG - establishing HTTPS connection: host=akiajb3ek3yzrouuilyq20181012210958353454.s3.amazonaws.com, kwargs={'timeout': 70, 'port': 443}\n",
      "DEBUG - Token: None\n",
      "DEBUG - StringToSign:\n",
      "PUT\n",
      "\n",
      "\n",
      "Sat, 13 Oct 2018 01:09:58 GMT\n",
      "/akiajb3ek3yzrouuilyq20181012210958353454/\n",
      "DEBUG - Signature:\n",
      "AWS AKIAJB3EK3YZROUUILYQ:6J/VrjsQhSp8fLfI8WqX8gJmXfM=\n",
      "DEBUG - Final headers: {'User-Agent': 'Boto/2.48.0 Python/3.6.5 Windows/10', 'Date': 'Sat, 13 Oct 2018 01:09:58 GMT', 'Authorization': 'AWS AKIAJB3EK3YZROUUILYQ:6J/VrjsQhSp8fLfI8WqX8gJmXfM=', 'Content-Length': '0'}\n",
      "DEBUG - Response headers: [('x-amz-id-2', 'IqHrigxOUdgzT6jpw0Gdwm3kB+MthgQzxddD4T0mQic+xhYbHWQMdOr6V7bEZEHQ+QXjRk/tYEk='), ('x-amz-request-id', '1D7524671737DA3E'), ('Date', 'Sat, 13 Oct 2018 01:09:59 GMT'), ('Location', '/akiajb3ek3yzrouuilyq20181012210958353454'), ('Content-Length', '0'), ('Server', 'AmazonS3')]\n",
      "bucket created\n",
      "Uploading %s to Amazon S3 bucket %s Problem2.zip akiajb3ek3yzrouuilyq20181012210958353454\n",
      "DEBUG - path=/Problem2\n",
      "DEBUG - auth_path=/akiajb3ek3yzrouuilyq20181012210958353454/Problem2\n",
      "DEBUG - Method: PUT\n",
      "DEBUG - Path: /Problem2\n",
      "DEBUG - Data: \n",
      "DEBUG - Headers: {'User-Agent': 'Boto/2.48.0 Python/3.6.5 Windows/10', 'Content-Type': 'application/x-zip-compressed', 'Content-MD5': 'GfhtLVdL28/wQl14C3yN1Q==', 'Content-Length': '138532661', 'Expect': '100-Continue'}\n",
      "DEBUG - Host: akiajb3ek3yzrouuilyq20181012210958353454.s3.amazonaws.com:443\n",
      "DEBUG - Port: 443\n",
      "DEBUG - Params: {}\n",
      "DEBUG - Token: None\n",
      "DEBUG - StringToSign:\n",
      "PUT\n",
      "GfhtLVdL28/wQl14C3yN1Q==\n",
      "application/x-zip-compressed\n",
      "Sat, 13 Oct 2018 01:09:59 GMT\n",
      "/akiajb3ek3yzrouuilyq20181012210958353454/Problem2\n",
      "DEBUG - Signature:\n",
      "AWS AKIAJB3EK3YZROUUILYQ:A951qL+fA0WjaXlFqvNmDW1zeK8=\n",
      "DEBUG - Final headers: {'User-Agent': 'Boto/2.48.0 Python/3.6.5 Windows/10', 'Content-Type': 'application/x-zip-compressed', 'Content-MD5': 'GfhtLVdL28/wQl14C3yN1Q==', 'Content-Length': '138532661', 'Expect': '100-Continue', 'Date': 'Sat, 13 Oct 2018 01:09:59 GMT', 'Authorization': 'AWS AKIAJB3EK3YZROUUILYQ:A951qL+fA0WjaXlFqvNmDW1zeK8='}\n",
      "..........DEBUG - Response headers: [('x-amz-id-2', 'J3XV3Pc0ZoT9/1l/GtuvyaYta9ZnZ5H4BUiZH41Z69f6InqIRxJofQpQSQjK7CBdxeRJL+uViFw='), ('x-amz-request-id', '980E2A2BBF479766'), ('Date', 'Sat, 13 Oct 2018 01:10:00 GMT'), ('ETag', '\"19f86d2d574bdbcff0425d780b7c8dd5\"'), ('Content-Length', '0'), ('Server', 'AmazonS3')]\n",
      "Zip File successfully uploaded to S3\n"
     ]
    }
   ],
   "source": [
    "##### Assignement-1 --Part 2\n",
    "############### Import Libraries ###############\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import logging # for logging\n",
    "import shutil #to delete the directory contents\n",
    "import glob\n",
    "import boto.s3\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "############### Initializing logging file ###############\n",
    "\n",
    "logger= logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "#fh is file header\n",
    "fh = logging.FileHandler('Problem2_log.log') #output the logs to a file\n",
    "fh.setLevel(logging.DEBUG) #setting loglevel to DEBUG\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s') #format for the output\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "#ch is console header\n",
    "ch = logging.StreamHandler(sys.stdout ) #print the logs in console as well\n",
    "ch.setLevel(logging.DEBUG) #setting loglevel to DEBUG\n",
    "formatter = logging.Formatter('%(levelname)s - %(message)s') #format for the output\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "############### Cleanup required directories ###############\n",
    "\n",
    "try:\n",
    "    if not os.path.exists('downloaded_zips'):\n",
    "        os.makedirs('downloaded_zips', mode=0o777)\n",
    "    else:\n",
    "        shutil.rmtree(os.path.join(os.path.dirname(__file__),'downloaded_zips'), ignore_errors=False)\n",
    "        os.makedirs('downloaded_zips', mode=0o777)\n",
    "    \n",
    "    if not os.path.exists('downloaded_zips_unzipped'):\n",
    "        os.makedirs('downloaded_zips_unzipped', mode=0o777)\n",
    "    else:\n",
    "        shutil.rmtree(os.path.join(os.path.dirname(__file__), 'downloaded_zips_unzipped'), ignore_errors=False)\n",
    "        os.makedirs('downloaded_zips_unzipped', mode=0o777)\n",
    "    logging.info('Directories cleanup complete.')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()     \n",
    "    \n",
    "############### Function to Download zips ###############\n",
    "def download_zip(url):\n",
    "    zips = []\n",
    "    try:\n",
    "        zips.append(urllib.request.urlretrieve(url, filename= 'downloaded_zips/'+url[-15:]))\n",
    "        if os.path.getsize('downloaded_zips/'+url[-15:]) <= 4515: #catching empty file\n",
    "            os.remove('downloaded_zips/'+url[-15:])\n",
    "            logging.warning('Log file %s is empty. Attempting to download for next date.', url[-15:])\n",
    "            return False\n",
    "        else:\n",
    "            logging.info('Log file %s successfully downloaded', url[-15:])\n",
    "            return True\n",
    "    except Exception as e: #Catching file not found\n",
    "        logging.warning('Log %s not found...Skipping ahead!', url[-15:])\n",
    "        return True\n",
    "\n",
    "############## Fetch all the command line arguments ###################\n",
    "CIK = str(sys.argv[1]) #CIK number is inputed\n",
    "year = str(sys.argv[2])\n",
    "acc_no = str(sys.argv[3]) #Account_number is inputed\n",
    "\n",
    "# method to use acc_no as input to create accession_number\n",
    "def dash(string):\n",
    "    if (len(string) == 18):\n",
    "        return string[:10] + \"-\" + string[10:12] + \"-\" + string[12:] # dashes are inputed at right index values to create accession_number \n",
    "    else:\n",
    "        print(\"Values are invalid\")\n",
    "        \n",
    "accession_no = dash(acc_no)\n",
    "\n",
    "#print(\"Year=\",year)\n",
    "#print(\"Access Key=\",accessKey)\n",
    "#print(\"Secret Access Key=\",secretAccessKey)\n",
    "#print(\"Location=\",inputLocation)\n",
    "\n",
    "############### Validate amazon keys ###############\n",
    "\n",
    "accessKey = input('accesskey ')\n",
    "secretAccessKey =input('secretAccessKey ')\n",
    "\n",
    "if not accessKey or not secretAccessKey:\n",
    "    logging.warning('Access Key and Secret Access Key not provided!!')\n",
    "    print('Access Key and Secret Access Key not provided!!')\n",
    "    exit()\n",
    "\n",
    "AWS_ACCESS_KEY_ID = str(sys.argv[4])\n",
    "AWS_SECRET_ACCESS_KEY = str(sys.argv[5])\n",
    "\n",
    "try:\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "            AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    print(\"Connected to S3\")\n",
    "\n",
    "except:\n",
    "    logging.info(\"Amazon keys are invalid!!\")\n",
    "    print(\"Amazon keys are invalid!!\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "############### Generate URLs and download zip for the inputted year ###############\n",
    "\n",
    "URL = \"http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/\"\n",
    "qtr_months = {'Qtr1':['01','02','03'], 'Qtr2':['04','05','06'], 'Qtr3':['07','08','09'], 'Qtr4':['10','11','12']}\n",
    "valid_years = range(2003,2017)\n",
    "days = range(1,32)\n",
    "\n",
    "if not year:\n",
    "    year = 2003\n",
    "    logging.warning('Program running for 2003 by default since you did not enter any Year.')\n",
    "\n",
    "if int(year) not in valid_years:\n",
    "    logging.error(\"Invalid year. Please enter a valid year between 2003 and 2016.\")\n",
    "    exit()\n",
    "\n",
    "logging.info('Initializing zip download.')\n",
    "\n",
    "url_final = []\n",
    "for key, val in qtr_months.items():\n",
    "    for v in val:\n",
    "        for d in days:\n",
    "            url = URL +str(year) +'/' +str(key) +'/' +'log' +str(year) +str(v) + str(format(d,'02d')) +'.zip'\n",
    "            if download_zip(url):\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "logging.info('All log files downloaded for %s', year)\n",
    "\n",
    "\n",
    "############### Unzip the logs and extract csv ###############\n",
    "try:\n",
    "    zip_files = os.listdir('downloaded_zips')\n",
    "    for f in zip_files:\n",
    "        z = zipfile.ZipFile(os.path.join('downloaded_zips', f), 'r')\n",
    "        for file in z.namelist():\n",
    "            if file.endswith('.csv'):\n",
    "                z.extract(file, r'downloaded_zips_unzipped')\n",
    "    logging.info('Zip files successfully extracted to folder: downloaded_zips_unzipped.')\n",
    "except Exception as e:\n",
    "        logging.error(str(e))\n",
    "        exit()\n",
    "\n",
    "\n",
    "############### Load the csvs into dataframe ###############\n",
    "try:\n",
    "    filelists = glob.glob('downloaded_zips_unzipped' + \"/*.csv\")\n",
    "    all_csv_df_dict = {period: pd.read_csv(period) for period in filelists}\n",
    "    logging.info('All the csv read into individual dataframes')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()\n",
    "                   \n",
    "                   \n",
    "############### The following section deals with DETECTING ANOMALIES, ###############\n",
    "############### HANDLING MISSING VALUES and computing ###############################\n",
    "############### SUMMARY METRICS for one dataframe at a time #########################\n",
    "\n",
    "try:\n",
    "    for key, val in all_csv_df_dict.items():\n",
    "        df = all_csv_df_dict[key]\n",
    "        #detecting null values\n",
    "        null_count = df.isnull().sum()\n",
    "        logging.info('Count of Null values for %s in all the variables:\\n%s ', key, null_count)\n",
    "        \n",
    "        # variable idx should be either 0 or 1\n",
    "        incorrect_idx = (~df['idx'].isin([0.0,1.0])).sum()\n",
    "        logging.info('There are %s idx which are not 0 or 1 in the log file %s', incorrect_idx, key) \n",
    "        \n",
    "        # variable norefer should be either 0 or 1\n",
    "        incorrect_norefer = (~df['norefer'].isin([0.0,1.0])).sum()\n",
    "        logging.info('There are %s norefer which are not 0 or 1 in the log file %s', incorrect_norefer, key) \n",
    "        \n",
    "        # variable noagent should be either 0 or 1\n",
    "        incorrect_noagent = (~df['noagent'].isin([0.0,1.0])).sum()\n",
    "        logging.info('There are %s noagent which are not 0 or 1 in the log file %s', incorrect_noagent, key) \n",
    "        \n",
    "        #remove rows which have no ip, date, time, cik or accession\n",
    "        df.dropna(subset=['cik'])\n",
    "        df.dropna(subset=['accession'])\n",
    "        df.dropna(subset=['ip'])\n",
    "        df.dropna(subset=['date'])\n",
    "        df.dropna(subset=['time'])\n",
    "        \n",
    "        #replace nan with the most used browser in data.\n",
    "        max_browser = pd.DataFrame(df.groupby('browser').size().rename('cnt')).idxmax()[0]\n",
    "        df['browser'] = df['browser'].fillna(max_browser)\n",
    "        \n",
    "        # replace nan idx with max idx\n",
    "        max_idx = pd.DataFrame(df.groupby('idx').size().rename('cnt')).idxmax()[0]\n",
    "        df['idx'] = df['idx'].fillna(max_idx)\n",
    "        \n",
    "        # replace nan code with max code\n",
    "        max_code = pd.DataFrame(df.groupby('code').size().rename('cnt')).idxmax()[0]\n",
    "        df['code'] = df['code'].fillna(max_code)\n",
    "        \n",
    "        # replace nan norefer with zero\n",
    "        df['norefer'] = df['norefer'].fillna('1')\n",
    "        \n",
    "        # replace nan noagent with zero\n",
    "        df['noagent'] = df['noagent'].fillna('1')\n",
    "        \n",
    "        # replace nan find with max find\n",
    "        max_find = pd.DataFrame(df.groupby('find').size().rename('cnt')).idxmax()[0]\n",
    "        df['find'] = df['find'].fillna(max_find)\n",
    "        \n",
    "        # replace nan crawler with zero\n",
    "        df['crawler'] = df['crawler'].fillna('0')\n",
    "        \n",
    "        # replace nan extention with max extention\n",
    "        max_extention = pd.DataFrame(df.groupby('extention').size().rename('cnt')).idxmax()[0]\n",
    "        df['extention'] = df['extention'].fillna(max_extention)\n",
    "        \n",
    "        # replace nan extention with max extention\n",
    "        max_zone = pd.DataFrame(df.groupby('zone').size().rename('cnt')).idxmax()[0]\n",
    "        df['zone'] = df['zone'].fillna(max_zone)\n",
    "    \n",
    "        # find mean of the size and replace null values with the mean\n",
    "        df['size'] = df['size'].fillna(df['size'].mean(axis=0))\n",
    "        \n",
    "        ##### Summary Metrics #####\n",
    "        #Compute mean size\n",
    "        df['size_mean'] = df['size'].mean(axis=0)\n",
    "        \n",
    "        #Compute maximum used browser\n",
    "        df['max_browser'] = pd.DataFrame(df.groupby('browser').size().rename('cnt')).idxmax()[0]\n",
    "        \n",
    "        #Compute distinct count of ip per month i.e. per log file\n",
    "        df['ip_count'] = df['ip'].nunique()\n",
    "        \n",
    "        #Compute distinct count of cik per month i.e. per log file\n",
    "        df['cik_count'] = df['cik'].nunique()\n",
    "    \n",
    "    logging.info('Rows removed where ip, date, time, cik or accession were null.')\n",
    "    logging.info('NaN values in browser replaced with maximum count browser.')\n",
    "    logging.info('NaN values in idx replaced with maximum count idx.')\n",
    "    logging.info('NaN values in code replaced with maximum count code.')\n",
    "    logging.info('NaN values in norefer replaced with 0.')\n",
    "    logging.info('NaN values in noagent replaced with 0.')\n",
    "    logging.info('NaN values in find replaced with maximum count find.')\n",
    "    logging.info('NaN values in crawler replaced with 0.')\n",
    "    logging.info('NaN values in extension replaced with maximum count extension.')\n",
    "    logging.info('NaN values in zone replaced with maximum count zone.')\n",
    "    logging.info('NaN values in size replaced with mean value of size.')\n",
    "    logging.info('New column added to dataframe: Mean of size.')\n",
    "    logging.info('New column added to dataframe: Max count of browser.')\n",
    "    logging.info('New column added to dataframe: Count of distinct ip per month.')\n",
    "    logging.info('New column added to dataframe: Count of distinct cik per month.')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()\n",
    "    \n",
    "############### Combining all dataframe and computing overall summary metric ###############\n",
    "# writing csv for all data\n",
    "try:\n",
    "    master_df = pd.concat(all_csv_df_dict)\n",
    "    master_df.to_csv('main_csv.csv')\n",
    "    logging.info('All dataframes of csvs are combined and exported as csv: main_csv.csv.')\n",
    "except Exception as e:\n",
    "    logging.error(str(e))\n",
    "    exit()\n",
    "    \n",
    "# write csv for summary of combined data.\n",
    "#try:\n",
    "#    master_df_summary = master_df.describe()\n",
    "#    master_df_summary.to_csv('master_df_summary.csv')\n",
    "#    logging.info('The summary metric of combined csv is generated and exported as csv: master_df_summary.csv .')\n",
    "#except Exception as e:\n",
    "#    logging.error(str(e))\n",
    "#   exit()\n",
    "\n",
    "############### Zip the csvs and logs ###############\n",
    "def zipdir(path, ziph):\n",
    "    ziph.write(os.path.join('main_csv.csv'))\n",
    "#    ziph.write(os.path.join('master_df_summary.csv'))\n",
    "    ziph.write(os.path.join('Problem2_log.log'))   \n",
    "\n",
    "zipf = zipfile.ZipFile('Problem2.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('/', zipf)\n",
    "zipf.close()\n",
    "logging.info('Compiled csv and log file zipped')\n",
    "    \n",
    "############### Upload the zip to AWS S3 ###############\n",
    "############### Fetch the location argument if provided, else user's system location is taken ############### \n",
    "\n",
    "try:   \n",
    "    ts = time.time()\n",
    "    st = datetime.datetime.fromtimestamp(ts)    \n",
    "    bucket_name = accessKey.lower()+str(st).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\",\"\").replace(\".\",\"\")\n",
    "    bucket = conn.create_bucket(bucket_name)\n",
    "    print(\"bucket created\")\n",
    "    zipfile = 'Problem2.zip'\n",
    "    print (\"Uploading %s to Amazon S3 bucket %s\", zipfile, bucket_name)\n",
    "    \n",
    "    def percent_cb(complete, total):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    k = Key(bucket)\n",
    "    k.key = 'Problem2'\n",
    "    k.set_contents_from_filename(zipfile,\n",
    "        cb=percent_cb, num_cb=10)\n",
    "    print(\"Zip File successfully uploaded to S3\")\n",
    "except:\n",
    "    logging.info(\"Amazon keys are invalid!!\")\n",
    "    print(\"Amazon keys are invalid!!\")\n",
    "    exit()\n",
    "############ EOF ############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
