{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - Directory Created\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b709b191c44a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Directory Created\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m \u001b[0mwebsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[0mtablelist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwebsite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[0mgenerate_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtablelist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b709b191c44a>\u001b[0m in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mcik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mdocnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"URL for the 10-q file for CIK = %s and Accession_no = %s is created\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mzero_cik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_cik\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcik\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[207]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tabulate\n",
    "import sys\n",
    "import urllib.request\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import zipfile\n",
    "import logging # for logging\n",
    "import glob\n",
    "import boto.s3\n",
    "from boto.s3.key import Key\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "logger= logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "#fh is file header\n",
    "fh = logging.FileHandler('Problem1_log.log') #output the logs to a file\n",
    "fh.setLevel(logging.DEBUG) #setting loglevel to DEBUG\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s') #format for the output\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "#ch is console header\n",
    "ch = logging.StreamHandler(sys.stdout ) #print the logs in console as well\n",
    "ch.setLevel(logging.DEBUG) #setting loglevel to DEBUG\n",
    "formatter = logging.Formatter('%(levelname)s - %(message)s') #format for the output\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#allCik = pd.read_csv(\"C:\\Users\\rishi\\Desktop\\ADS_TEAM_SRK\\assignment1_EDGAR\\ALL_CIK.csv\", low_memory= False)\n",
    "# # Check for valid CIK\n",
    "# In[6]:\n",
    "#function to check if entered CIK is valid\n",
    "#def CheckandAcceptCIK(num):\n",
    "    #flag = False\n",
    "    #for i in allCik[\"CIK\"]:\n",
    "        #if (num == i):\n",
    "            #flag = True\n",
    "            \n",
    "#if(flag == False):\n",
    "        #print(\"Invalid CIK. Please run the program again\")   \n",
    "    #else:\n",
    "        #return str(num)\n",
    "        \n",
    "\n",
    "\n",
    "# # Add Leading Zeros\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#function to add leading zeroes \n",
    "\n",
    "\n",
    "\n",
    "def calc_cik(cik):\n",
    "\n",
    "    cik_str = str(cik)\n",
    "    length_cik = len(cik_str)\n",
    "    final_length = 10 - length_cik\n",
    "    i=0\n",
    "    while i < final_length:\n",
    "        cik_str ='0' + cik_str\n",
    "        i= i+1\n",
    "        \n",
    "    return cik_str\n",
    "\n",
    "\n",
    "# # Calculate Financial Year Part\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#function to calculate financial year part which is added to our link\n",
    "# # Generating the URL\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "def start():\n",
    "    condition = True\n",
    "    while(condition == True):\n",
    "        cik = str(sys.argv[1])\n",
    "        year= str(sys.argv[2])\n",
    "        docnumber = str(sys.argv[3])\n",
    "        logging.info(\"URL for the 10-q file for CIK = %s and Accession_no = %s is created\", cik, docnumber)\n",
    "        zero_cik = calc_cik(cik)\n",
    "        year = year[-2:]\n",
    "        website = \"https://www.sec.gov/Archives/edgar/data/\" + cik+\"/\" + zero_cik+\"\"+year[-2:]+docnumber +\"/\" + zero_cik+ \"-\" + year[-2:]+\"-\" +docnumber+\"-index.htm\"\n",
    "        try:\n",
    "            r = requests.head(website)\n",
    "            \n",
    "            # prints the int of the status code. Find more at httpstatusrappers.com :)\n",
    "        except requests.ConnectionError:\n",
    "            print(\"Sorry you got Bad Internet. Let's try this again at a later time\")\n",
    "            \n",
    "        \n",
    "        if(r.status_code == 200):\n",
    "            print(\"Website Accessed\")\n",
    "            logging.info(\"Link is generated\")\n",
    "            \n",
    "            condition = False\n",
    "        else:\n",
    "            print(\"Failed to connect basis data provide, kindly re-enter correct details\")\n",
    "            logging.info(\"Wrong input for CIK and Docnumber\")\n",
    "\n",
    "    return website\n",
    "\n",
    "\n",
    "# In[182]:\n",
    "\n",
    "\n",
    "def scrape(website):\n",
    "    res = requests.get(website)\n",
    "    soup = BeautifulSoup(res.content,'lxml')\n",
    "    #tables = soup.find('table')\n",
    "    tbl = soup.findAll('table')\n",
    "    print(len(tbl))\n",
    "\n",
    "    for table in tbl:\n",
    "        for tr in table.findAll('tr'):\n",
    "            for td in tr.findAll('td')[2:4]:\n",
    "                filing_type = td.string\n",
    "                if filing_type=='10-Q':\n",
    "                    gen_links = [a['href'] for a in tr.findAll('a')]\n",
    "                    print('generated-link is:   ',gen_links)\n",
    "                    for links in gen_links:\n",
    "                        web_link = 'https://www.sec.gov' + links\n",
    "                        print('web-link is:   ',web_link)\n",
    "                        logging.info(\"10 Link generated\")\n",
    "                        \n",
    "    tablelist = []\n",
    "\n",
    "    soup = BeautifulSoup((urllib.request.urlopen(web_link)),\"html.parser\")\n",
    "    tables = soup.find_all('table')\n",
    "    for table in tables: \n",
    "        for tr in table.find_all('tr'):\n",
    "            i = 0\n",
    "            for td in tr.findChildren('td'):\n",
    "                if (\"background\" in str(td.get('style'))):\n",
    "                    tablelist.append(table)\n",
    "                    i = 1\n",
    "                    break\n",
    "            if(i == 1):\n",
    "                break\n",
    "    return tablelist            \n",
    "\n",
    "\n",
    "# In[208]:\n",
    "\n",
    "\n",
    "def generate_csv(tablelist):\n",
    "    destination = 'all_csv'\n",
    "    print('length of table in generate_csv is:',len(tablelist))\n",
    "    i = 1\n",
    "    for new_tab in tablelist:\n",
    "        df = pd.read_html(str(new_tab))\n",
    "        file_name = 'my_data'+str(i)+ '.csv'\n",
    "        \n",
    "        df[0].to_csv(os.path.join(destination,file_name))\n",
    "        i = i + 1 \n",
    "        \n",
    "    print('CSV Generated and Zip created')\n",
    "    shutil.make_archive(r'zip_all_csv', 'zip', r'all_csv')\n",
    "    logging.info(\"CSV has been made and Zipped\")\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "x = 'all_csv'\n",
    "if not os.path.exists(x):\n",
    "    os.makedirs(x)\n",
    "logging.info(\"Directory Created\")\n",
    "\n",
    "website = start()\n",
    "tablelist = scrape(website)\n",
    "generate_csv(tablelist)\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AWS_ACCESS_KEY_ID = str(sys.argv[4])\n",
    "AWS_SECRET_ACCESS_KEY = str(sys.argv[5])\n",
    "\n",
    "try:\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "            AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    print(\"Connected to S3\")\n",
    "\n",
    "except:\n",
    "    logging.info(\"Amazon keys are invalid!!\")\n",
    "    print(\"Amazon keys are invalid!!\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts)    \n",
    "bucket_name = AWS_ACCESS_KEY_ID.lower()+str(st).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\",\"\").replace(\".\",\"\")\n",
    "bucket = conn.create_bucket(bucket_name)\n",
    "print(\"bucket created\")\n",
    "zipfile = 'zip_all_csv.zip'\n",
    "print (\"Uploading %s to Amazon S3 bucket %s\", zipfile, bucket_name)\n",
    "    \n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "k = Key(bucket)\n",
    "k.key = 'all_csv'\n",
    "k.set_contents_from_filename(zipfile,\n",
    "cb=percent_cb, num_cb=10)\n",
    "print(\"Zip File successfully uploaded to S3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
