{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # Import libraries\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tabulate\n",
    "import sys\n",
    "\n",
    "\n",
    "# # Importing CSV Data\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#allCik = pd.read_csv(\"C:\\Users\\rishi\\Desktop\\ADS_TEAM_SRK\\assignment1_EDGAR\\ALL_CIK.csv\", low_memory= False)\n",
    "\n",
    "\n",
    "# # Check for valid CIK\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#function to check if entered CIK is valid\n",
    "\n",
    "#def CheckandAcceptCIK(num):\n",
    "    #flag = False\n",
    "    #for i in allCik[\"CIK\"]:\n",
    "        #if (num == i):\n",
    "            #flag = True\n",
    "            \n",
    "    #if(flag == False):\n",
    "        #print(\"Invalid CIK. Please run the program again\")\n",
    "        \n",
    "        \n",
    "    #else:\n",
    "        #return str(num)\n",
    "        \n",
    "\n",
    "\n",
    "# # Add Leading Zeros\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#function to add leading zeroes \n",
    "\n",
    "\n",
    "def calc_cik(cik):\n",
    "\n",
    "    cik_str = str(cik)\n",
    "    length_cik = len(cik_str)\n",
    "    final_length = 10 - length_cik\n",
    "    i=0\n",
    "    while i < final_length:\n",
    "        cik_str ='0' + cik_str\n",
    "        i= i+1\n",
    "        \n",
    "    return cik_str\n",
    "\n",
    "\n",
    "# # Calculate Financial Year Part\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#function to calculate financial year part which is added to our link\n",
    "# # Generating the URL\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def start():\n",
    "    condition = True\n",
    "    while(condition == True):\n",
    "        cik = str(sys.argv[1])\n",
    "        year= str(sys.argv[2])\n",
    "        docnumber = str(sys.argv[3])\n",
    "        \n",
    "        zero_cik = calc_cik(cik)\n",
    "        year = year[-2:]\n",
    "        website = \"https://www.sec.gov/Archives/edgar/data/\" + cik+\"/\" + zero_cik+\"\"+year[-2:]+\"000007\" +\"/\" + zero_cik+ \"-\" + year[-2:]+\"-\" +docnumber+\"-index.htm\"\n",
    "        print(website)\n",
    "        try:\n",
    "            r = requests.head(website)\n",
    "            \n",
    "            # prints the int of the status code. Find more at httpstatusrappers.com :)\n",
    "        except requests.ConnectionError:\n",
    "            print(\"Sorry you got Bad Internet. Let's try this again at a later time\")\n",
    "        \n",
    "        if(r.status_code == 200):\n",
    "            print(\"Website Accessed\")\n",
    "            condition = False\n",
    "        else:\n",
    "            print(\"Failed to connect basis data provide, kindly re-enter correct details\")\n",
    "        return website        \n",
    "\n",
    "website = start()\n",
    "website\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "res = requests.get(website)\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#table = soup.find_all('table')[0]\n",
    "#df = pd.read_html(str(table))\n",
    "#df[0].to_csv('my_data.csv')\n",
    "tables = soup.find_all('table')\n",
    "i = 1\n",
    "#len(tables)\n",
    "for table in tables:\n",
    "    df = pd.read_html(str(table))\n",
    "    df[0].to_csv('my_data'+ str(i) + '.csv')\n",
    "    i = i + 1\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "res = requests.get(website)\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#tables = soup.find('table')\n",
    "tbl = soup.findAll('table')\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "for table in tbl:\n",
    "    for tr in table.findAll('tr'):\n",
    "        for td in tr.findAll('td')[:2]:\n",
    "            filing_type = td.string\n",
    "            if filing_type=='10-Q':\n",
    "                gen_links = [a['href'] for a in tr.findAll('a')]\n",
    "                print('generated-link is:   ',gen_links)\n",
    "                for links in gen_links:\n",
    "                    web_link = 'https://www.sec.gov' + links\n",
    "                    print('web-link is:   ',web_link)\n",
    "                    res_new = requests.get(web_link)\n",
    "                    soup_new = BeautifulSoup(res_new.content,'lxml')\n",
    "                    tables_new = soup_new.find_all('table', attrs={'border':\"1\", 'cellpadding':\"0\", 'cellspacing':\"0\", 'style':\"border:none;border-collapse:collapse;width:100%;\"})\n",
    "                    i = 1\n",
    "                    print('length of table is:',len(tables_new))\n",
    "                    for new_tab in tables_new:\n",
    "                        df = pd.read_html(str(new_tab))\n",
    "                        df[0].to_csv('my_data'+ str(i) + '.csv')\n",
    "                        i = i + 1\n",
    "                        #print(\"Successful\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
